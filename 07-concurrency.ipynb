{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff704263",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### STA 141B Data & Web Technologies for Data Analysis\n",
    "\n",
    "## Lecture 6, 1/22/26, Concurrency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d3897e-d11f-4947-8877-9ba789eb27e3",
   "metadata": {},
   "source": [
    "Announcements\n",
    "\n",
    "- Group registration deadline this Friday"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d6f0bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Today's Topics\n",
    "\n",
    " - Concurrency\n",
    "     - Threads and Processes\n",
    "     - I/O-Concurrency\n",
    "         - `threading`\n",
    "     - CPU-Concurrency (Parallelization)\n",
    "         - `multiprocessing` \n",
    "         - `Spark`\n",
    " \n",
    "### References\n",
    "- [SuperFastPython](https://superfastpython.com/thread-vs-process/) by Jason Brownlee\n",
    "- [An introduction to parallel programming](https://sebastianraschka.com/Articles/2014_multiprocessing.html) by Sebastian Raschka\n",
    "- [Speed Up Your Python Program With Concurrency](https://realpython.com/python-concurrency/) by Jim Anderson\n",
    "- [An Intro to Threading in Python](https://realpython.com/intro-to-python-threading/) by Jim Anderson\n",
    "- [Parallelization in Python](https://towardsdatascience.com/3-methods-for-parallelization-in-spark-6a1a4333b473) by Ben Weber"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44dc81e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Threads and Processes\n",
    "\n",
    "A computer can have multiple CPUs, each CPU has multiple cores (e.g., two quad-core CPUs). \n",
    "All the CPUs are connected to memory (e.g., 64G memory). \n",
    "CPU cores can execute in parallel. \n",
    "\n",
    "<div>\n",
    "<img src=\"../images/fig1.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58803ce1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A __process__ is the *operating system’s spawned and controlled entity that encapsulates an executing application* ([Breshears: The Art of Concurrency](https://amzn.to/3J74TRr)). \n",
    "\n",
    "A __thread__ is a path of execution which belongs to a process. \n",
    "\n",
    "Each thread belongs to a process. In single-threaded processes, the process contains one thread. In multithreaded processes, the process contains more than one thread, and the process is accomplishing a number of things at the same time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed164f3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Threads can share memory within a process. This means that functions executed in new threads can access the same data and state. These might be global variables or data shared via function arguments. As such, sharing state between threads is straightforward.\n",
    "\n",
    "Threads are sometimes called lightweight processes because they have their own stack but can access shared data. \n",
    "\n",
    "<div>\n",
    "<img src=\"../images/fig3.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171f70e3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "On the other hand, processes are 'share nothing', i.e., they independently execute without sharing memory or state. This makes it easier to turn into a distributed application, but typically, sharing data between processes requires explicit mechanisms.\n",
    "\n",
    "<div>\n",
    "<img src=\"../images/fig4.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0677f060",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Python allows to execute code using the principle of __global interpreter lock__ (GIL). This means that only one thread can be executed at a time. This simplifies implementation, but makes it more difficult to execute code concurrently. \n",
    "\n",
    "Today, we will explore the advantages of executing multiple processes and threads and discuss under what circumstances which approach is most adequate. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352750d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are two major kind of tasks, that will slow down your program: CPU-bound and I/O-bound.\n",
    "\n",
    "__I/O-bound tasks__ cause your program to slow down because it frequently must wait for input/output (I/O) from some external resource. They arise when your program interacts with other sources, i.e., when your are *requesting* data from another source. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0984bbb-cce0-4cf2-b3b7-d8575c3ff599",
   "metadata": {},
   "source": [
    "- CPU: 100_000_000_000 instructions per second (Intel i7)\n",
    "- 10_000_000 memory references per second\n",
    "- 500 disc seeks per second\n",
    "- 7 pings from US to Europe (and back) per second\n",
    "\n",
    "Thus, if you are waiting for a disc seek to complete or for data from the web, you could do a LOT of calculations in between."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acafebe",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=https://files.realpython.com/media/IOBound.4810a888b457.png style=\"width: 1500px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d51c2e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__CPU-bound tasks__ are those that require a lot of *computational* effort to complete. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9792b789",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=https://files.realpython.com/media/CPUBound.d2d32cb2626c.png style=\"width: 1700px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc078db",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We will use threads and the module `threading` for I/O-bound tasks and processes and the module `multiprocessing` for CPU-bound tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1b8610",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### I/O-Concurrency\n",
    "\n",
    "We’ll start with a non-concurrent version of this a I/O-bound task. Namely, we will use `requests` to request data from a [website](https://homepage.univie.ac.at/nicolai.amann/). For `request.Session`, see [here](https://requests.readthedocs.io/en/latest/user/advanced/) and [docs](https://requests.readthedocs.io/en/latest/api/?#requests.Session). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a93301",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests, time\n",
    "\n",
    "def download_site(url, session):\n",
    "    session.get(url) # fetch information from url \n",
    "    # ... do something ... \n",
    "    \n",
    "def download_all_sites(sites):\n",
    "    session = requests.Session()\n",
    "    [download_site(url, session) for url in sites]\n",
    "        \n",
    "def task(): \n",
    "    sites = [\"https://homepage.univie.ac.at/nicolai.amann/\"] * 20\n",
    "    start_time = time.time()\n",
    "    download_all_sites(sites)\n",
    "    print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bbfd47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "task()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4079ebd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We will now use concurrent threads that accomplish the same task, retrieving information by executing `requests.get` more efficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7e4be0-1fbb-4b32-9d7a-ebb0a53bbd3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import concurrent.futures, threading\n",
    "\n",
    "def download_site(url, session):\n",
    "    session.get(url) # fetch information from url \n",
    "    # ... do something ... \n",
    "    \n",
    "def download_all_sites(sites):\n",
    "    session = requests.Session()\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        executor.map(lambda u: download_site(u, session), sites)\n",
    "        \n",
    "def task(): \n",
    "    sites = [\"https://homepage.univie.ac.at/nicolai.amann/\"] * 20\n",
    "    start_time = time.time()\n",
    "    download_all_sites(sites)\n",
    "    print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfe88df-d22f-4610-b900-e87ecbdeb333",
   "metadata": {},
   "outputs": [],
   "source": [
    "task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284bab80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import concurrent.futures, threading\n",
    "\n",
    "thread_local = threading.local() # instantiates thread to create local data (here: session-attr.)\n",
    "\n",
    "def download_site(url):\n",
    "    session = get_session()\n",
    "    session.get(url)\n",
    "    # ... do something ... \n",
    "\n",
    "def download_all_sites(sites):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "        executor.map(download_site, sites)\n",
    "\n",
    "def get_session():\n",
    "    '''Create a new requests.Session if there is none in thread_local'''\n",
    "    if not hasattr(thread_local, \"session\"): \n",
    "        thread_local.session = requests.Session()\n",
    "    return thread_local.session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22615b2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We have created a `concurrent.futures.ThreadPoolExecutor`. It creates four threads that are run concurrently. \n",
    "\n",
    "Also, each thread will become its own separate `requests.Session`. This is one of the interesting and difficult issues with threading. Because the operating system is in control of switching between threads, any data that is shared between the threads needs to be protected, or thread-safe. Unfortunately `requests.Session` is not thread-safe. If untreated, *race conditions* can produce hard-to-detect bugs. \n",
    "\n",
    "Here, we use `threading.local()` to instantiate an object that looks like a global but is specific to each individual thread. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a96540c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "task()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25bd665",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The code above is faster than the non-concurrent version, because the I/O-bound has been circumvented. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754b31dc",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=https://files.realpython.com/media/Threading.3eef48da829e.png style=\"width: 900px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48a57dd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### CPU-Concurrency (Parallelization)\n",
    "\n",
    "The above example of concurrency run only on a single CPU. This is due to the GIL. The `multiprocessing` module breaks down that barrier and runs code across multiple CPUs. \n",
    "\n",
    "It does this by creating a new instance of the Python interpreter (a new process) to run on each CPU and then farming out part of your program to run on it.  Bringing up a separate Python interpreter is not as fast as starting a new thread in the current Python interpreter. Regarding `.set_start_method`, see [here](https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801a8412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "multiprocessing.cpu_count() # number of cores on laptop/computer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b092d24b-481c-4a81-ae44-f37eff2ccb85",
   "metadata": {},
   "source": [
    "Note that on Windows OS, the `fork` method is not available. You must use `spawn` instead.\n",
    "However, there are two more rules if using the `spawn` method:\n",
    "- You must add the following lines to the code:\n",
    "  ```python\n",
    "  if __name__ == '__main__':\n",
    "      task()\n",
    "  ```\n",
    "- Also, this does not work within the Jupyter Notebook. Rather, the code must be saved in an .py file and executed separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bebb16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "session = None\n",
    "multiprocessing.set_start_method(\"fork\", True) # new process will be a copy from previous process\n",
    "\n",
    "def set_global_session():\n",
    "    global session\n",
    "    if not session:\n",
    "        session = requests.Session()\n",
    "\n",
    "def download_site(url):\n",
    "    session.get(url)\n",
    "    # ... do something ... \n",
    "\n",
    "def download_all_sites(sites):\n",
    "    with multiprocessing.Pool(initializer=set_global_session) as pool: # change processes!\n",
    "        pool.map(download_site, sites)\n",
    "    \n",
    "task()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c503bc19",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We may even be faster than with `threading`, since we are running up to 8 processes in parallel, but `multiprocessing` cannot scale beyond the number of cores in your local machine. \n",
    "The default argument `processes` of `multiprocessing.pool.Pool` ([docs](https://docs.python.org/3/library/multiprocessing.html?#module-multiprocessing.pool)), is the number of available cores on the machine. \n",
    "\n",
    "Remember that each process has its own memory space (share-nothing). That means that they cannot share things like a `requests.Session` object. We don’t want to create a new Session each time the function is called, you want to create one for each process, which calls `request.get` multiple times after another. \n",
    "\n",
    "The `initializer` function parameter is built for just this case. We initialize a global `session` variable to hold the single `requests.Session` *for each process*. Because each process has its own memory space, the global for each one will be different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779e2832",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "<img src=https://files.realpython.com/media/MProc.7cf3be371bbc.png style=\"height: 600px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05368937",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This course will deal with fetching information from the web, usually via requests. While these requests will usually be bound by third partys who maintain the servers we are requesting from as well, they are in essence I/O-bound task. `multiprocessing` however is useful for CPU-bound tasks. Consequently, lets consider a computational problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edef6c4a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For the purposes of our example, we’ll use a somewhat silly function to create something that takes a long time to run on the CPU. This function computes the sum of the squares of each number from 0 to the passed-in value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1406ac99",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def problem(number):\n",
    "    return sum(i * i for i in range(number))\n",
    "\n",
    "def find_sums(numbers):\n",
    "    for number in numbers:\n",
    "        problem(number)\n",
    "\n",
    "def task():\n",
    "    numbers = [5_000_000 + x for x in range(20)]\n",
    "    start_time = time.time()\n",
    "    find_sums(numbers)\n",
    "    print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9ef724",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "task()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d247d32",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This code calls `problem` 20 times with a different large number each time. It does all of this on a single thread in a single process on a single CPU. The execution timing diagram looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c315448",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=https://files.realpython.com/media/CPUBound.d2d32cb2626c.png style=\"width: 1600px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d55b3f5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Since there is no I/O waiting time, `threading` will not speed up this problem. We can however speed the computation by using our multiple cores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87f2626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# multiprocessing.set_start_method(\"fork\", True) # has already been set\n",
    "def find_sums(numbers):\n",
    "    pool = multiprocessing.Pool(processes = 8)\n",
    "    return pool.map(problem, numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83043ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cfb2e3-3048-4c53-89f0-f1f66cf572d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d95d01-42d9-4570-b9c5-3fb5d63f0cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem(number):\n",
    "    return sum(i * i for i in range(number))\n",
    "\n",
    "def find_sums(numbers):\n",
    "    pool = multiprocessing.Pool(processes = 8)\n",
    "    return pool.map(problem, numbers)\n",
    "\n",
    "def task():\n",
    "    numbers = [5_000_000 + x for x in range(20)]\n",
    "    start_time = time.time()\n",
    "    vl_numbers = find_sums(numbers)\n",
    "    print(time.time() - start_time)\n",
    "    print(vl_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4740af-700a-4e72-9b79-545594c15c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a4b2ee-39e1-4078-8eb1-e1e3e92083cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceaa426",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This code is similar as for the I/O-bound problem, but here you don’t need to worry about the `requests.Session` object. Notably, the speed-up is not equal to the number of cores, as each process has to set up its own Python interpreter. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b72c9cc",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=https://files.realpython.com/media/CPUMP.69c1a7fad9c4.png style=\"height: 400px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1facef36",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "While this codes is easy and fast. All the single processes are automatically taken care of with `multiprocessing.Pool`. The results returned by `problem` are gathered by `multiprocessing.map` as a <kbd>list</kbd> type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c97ec85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "find_sums(range(0, 4)) # returns a list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92cea47",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "However, many solution require communication between the processes. This can add some complexity to your solution that a non-concurrent program would not need to deal with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a248b939",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A `multiprocessing.Queue` object provides a mechanism to pass data between a parent process and the descendent processes of it. It adheres the *first in first out* principle. We can retrieve with the `multiprocessing.get` method and set with the `multiprocessing.put` method. \n",
    "\n",
    "<div>\n",
    "<img src=https://media.geeksforgeeks.org/wp-content/uploads/multiprocessing-python-4.png style=\"width: 700px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d2430a",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "q = multiprocessing.Queue()\n",
    "def myfun(q, i): \n",
    "    q.put(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468886ff-a474-4410-a650-d27ff4839f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.empty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c28dee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize process\n",
    "processes = [multiprocessing.Process(target=myfun, args = (q, i)) for i in range(4)]\n",
    "processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da8edec-e64b-41d0-a9be-77368f247ce8",
   "metadata": {},
   "source": [
    "Report snapshot of the current processes number 33 (without the keyword grep)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce64c44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ps aux | grep \"[5]44\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833f44bc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The processess are initialized but not yet executed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d332f66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run processes\n",
    "for process in processes:\n",
    "    process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71474cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# join processes\n",
    "for process in processes:\n",
    "    process.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4b4480",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The main purpose of `multiprocessing.join` ([docs](https://docs.python.org/3/library/multiprocessing.html?#multiprocessing.Process.join)) is to ensure that a child process has completed before the main process does anything that depends on the work of the child process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a834ede7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9464f3",
   "metadata": {},
   "source": [
    "The value `exitcode=0` means that the process has been completed successfully, without error ([docs](https://docs.python.org/3/library/multiprocessing.html?#multiprocessing.Process.exitcode)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14c5659",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "q.empty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f30a3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[q.get() for process in processes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9047275e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q.empty()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77178fd1",
   "metadata": {},
   "source": [
    "While `multiprocessing` allows you to steer the processes directly, many statistical problems are already implemented and ready for parallel computing, e.g. via `Spark`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422e7ad1-bf73-4fa8-95fd-f337287777d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ec636d-4f65-4762-a931-0abfe44719b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "import time\n",
    "\n",
    "def producer(q, items_to_produce):\n",
    "    for i in range(items_to_produce):\n",
    "        item = f\"Item {i}\"\n",
    "        print(f\"Producer: Putting {item}\")\n",
    "        q.put(item)\n",
    "        time.sleep(0.1) # Simulate work\n",
    "    q.put(None)\n",
    "\n",
    "def consumer(q):\n",
    "    while True:\n",
    "        item = q.get()\n",
    "        if item is None: # Check for sentinel value\n",
    "            break\n",
    "        print(f\"Consumer: Got {item}\")\n",
    "        time.sleep(0.2) # Simulate work\n",
    "\n",
    "queue = Queue()\n",
    "    \n",
    "p1 = Process(target=producer, args=(queue, 5))\n",
    "c1 = Process(target=consumer, args=(queue,))\n",
    "\n",
    "p1.start()\n",
    "c1.start()\n",
    "\n",
    "p1.join()\n",
    "c1.join()\n",
    "\n",
    "if queue.empty():\n",
    "    print(\"Main: All processes finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4e135a-4a84-4d6b-916f-f09ceaa609ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc6b509a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Spark\n",
    "\n",
    "Apache Spark is a computational engine that works with huge sets of data by processing them in parallel and batch systems. Spark is written in Scala, and [PySpark](https://www.dominodatalab.com/data-science-dictionary/pyspark) was released to support the collaboration of Spark and Python. \n",
    "\n",
    "The key data type used in PySpark is the Spark dataframe. This object can be thought of as a table distributed across a cluster, and has functionality that is similar to dataframes in `pandas`. If you want to do distributed computation using `PySpark`, then you’ll need to perform operations on Spark dataframes and not other Python data types.\n",
    "\n",
    "Here we explore how to perform tasks using `PySpark`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e9ec7e-705d-4ead-9d0e-846c626e40b4",
   "metadata": {},
   "source": [
    "Note: Unfortunately, just pip installing PySpark may not be enough to use the following code. Sometimes the installed JavaScript version on your PC/laptop is not matching the requirement for PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e677095",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89a93ce",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We consider a simple regression model for predicting house prices. Lets consider the non-serialized version first: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca27e6fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165dd157",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the california housing data set\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# convert to a Pandas Data Frame\n",
    "housing_pd = pd.DataFrame(data= np.c_[housing['data'],housing['target']], \n",
    "                          columns= np.append(housing['feature_names'], 'target')).sample(frac=1) \n",
    "\n",
    "# concatenate data\n",
    "# get all the data (fraction of 1 = 100%)\n",
    "# sample chooses without replacement: thus, we get a random ordering!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7282c01d-a402-497d-8968-4c114e9c2a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43213007-5492-4bb4-a2e1-c5e5adcec75b",
   "metadata": {},
   "source": [
    "California housing dataset.\n",
    "\n",
    "This dataset was obtained from the StatLib repository. https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
    "\n",
    "The data contains 20,640 observations on 9 variables.\n",
    "\n",
    "This dataset contains the average house value as target variable\n",
    "and the following input variables (features): median income,\n",
    "housing median age, average rooms, average bedrooms, population,\n",
    "average occupation, latitude, and longitude in that order.\n",
    "\n",
    "References:\n",
    "\n",
    "Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
    "Statistics and Probability Letters, 33:291-297, 1997."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7274f9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "housing_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699c21de",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "housing_pd.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0545cc78-2b59-47f8-bc23-6c4e8faf0553",
   "metadata": {},
   "source": [
    "Attribute Information:\n",
    "- MedInc: median income in block group\n",
    "- HouseAge: median house age in block group\n",
    "- AveRooms: average number of rooms per household\n",
    "- AveBedrms: average number of bedrooms per household\n",
    "- Population: block group population\n",
    "- AveOccup: average number of household members\n",
    "- Latitude: block group latitude\n",
    "- Longitude: block group longitude\n",
    "\n",
    "The target variable is the median house value for California districts, expressed in hundreds of thousands of dollars ($100,000).\n",
    "\n",
    "This dataset was derived from the 1990 U.S. census, using one row per census block group. A block group is the smallest geographical unit for which the U.S. Census Bureau publishes sample data (a block group typically has a population of 600 to 3,000 people).\n",
    "\n",
    "A household is a group of people residing within a home. Since the average number of rooms and bedrooms in this dataset are provided per household, these columns may take surprisingly <em>large values for block groups with few households and many empty houses, such as vacation resorts</em>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecb1b22-4423-452b-bfea-58f9153a6914",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_pd.index.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b591418-faa3-4a86-896a-a219555ce4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c701ff5-665c-4bf6-b179-e9afa300d282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "print(pyspark.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a57281-66de-4c32-b4bb-9d9ead01c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.stop()\n",
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc23d69",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "sc = SparkContext('local') # Create an instance of SparkContext. Only run locally, i.e., on this laptop\n",
    "spark = SparkSession(sc) # allows to use PySpark for DB, dataframes, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee2d741-abf0-4be6-b36e-e2ae63296a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.stop()/spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10789744-246f-45b5-8bc7-d3e0f306fda2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### DO NOT EXECUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdf9845-450d-4d34-87db-c8871c218903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# This safely gets an existing session or creates a new one\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"MyTestApp\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cbde82-b674-4b51-9ec5-c7b5eef6088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"MySession\").getOrCreate()\n",
    "\n",
    "# This silences the \"INFO\" and \"WARN\" logs after startup\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99890a61-e7c0-4eb0-8aee-aa6ab0517e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--driver-java-options \"-Djava.security.manager=allow\" pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5779c5ee-fd49-4545-94be-cc0a584ecd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FixTest\") \\\n",
    "    .getOrCreate() # Removed the security manager config\n",
    "\n",
    "print(\"Spark Session Created Successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8365cd9d-1eb0-4bde-89a8-705cc7010425",
   "metadata": {},
   "source": [
    "##### EXECUTION MAY START AGAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d44ab6",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# convert to a Spark data frame\n",
    "housing_sp = spark.createDataFrame(housing_pd) # convert to sparkDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab057548-5cb4-4ce9-8dff-2dfc06a49485",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(housing_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cddd49",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "features = housing_sp.schema.names[:] # define the features to be all the names above\n",
    "target = features.pop() # remove the last one (the target), and define it as the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82335ff3-8c3d-4995-9f42-b0783796e387",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# alternatively, we also could have used the following code\n",
    "features = housing_sp.schema.names[:-1] # define the features to be all but the last one of the names above\n",
    "target = housing_sp.schema.names[-1] # define the last feature to be the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe5205f-422c-488b-8d71-a9c4a54ef639",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49c77cb",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# convert to vector representation for MLlib\n",
    "assembler = VectorAssembler(inputCols=features, outputCol=\"features\" ) # creates a vector consisting of all features. They are distinguished by their column name.\n",
    "housing = assembler.transform(housing_sp).select('features', 'target') # creates a new dataframe consisting and selects the features and target variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ce0d1c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "See [docs](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegression.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0753108",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# linear regresion with Spark\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18276e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# linear regression with penalization\n",
    "lr = LinearRegression(labelCol=\"target\", featuresCol=\"features\", \n",
    "                      elasticNetParam = 1.0, # lasso / l1-penalization\n",
    "                      standardization = True, \n",
    "                      fitIntercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0020ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lrparamGrid = (ParamGridBuilder()\n",
    "               .addGrid(lr.regParam, [0.001, 0.01, 0.1, 0.2, 0.5, 0.75, 1.0, 1.5, 2.0]) # the Lasso regularizationParameter can either be 0.001, 0.01, etc.\n",
    "               .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccffb11",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "lrevaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"target\", metricName=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc9bbe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create 10-fold CrossValidator\n",
    "lrcv = CrossValidator(estimator = lr, # base ML algorithm to be trained and evaluated\n",
    "                      estimatorParamMaps = lrparamGrid, # possible parameters\n",
    "                      evaluator = lrevaluator, # defines the metric to be optimized\n",
    "                      numFolds = 10) # number of folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457ad1c1",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Run cross validations\n",
    "lrcvModel = lrcv.fit(housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecc51b6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "See [docs](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegressionTrainingSummary.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640c26fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get Model Summary Statistics\n",
    "lrcvSummary = lrcvModel.bestModel.summary\n",
    "lrcvSummary.meanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5659f62f-4f46-4997-a4b8-6b9ca7b4f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lrcvModel.bestModel.extractParamMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c8c4f0-b818-4d14-bda5-4a594c9c6398",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrcvModel.bestModel.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1231f009",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrcvModel.bestModel.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05c85cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_sp.schema.names[:-1] # last one is the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cacea8-a7d5-407e-82f5-9b7780f9379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "{name: np.round(value,3) for value,name in zip(lrcvModel.bestModel.coefficients, housing_sp.schema.names[:-1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08caecbe-b0d8-43cf-a82c-38d5753c61fc",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "housing_pd.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceebaa1-744e-4ff4-8b85-5466f46c586b",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "- Median Income influences the housing prices.\n",
    "- Surprisingly, older houses are (slightly) more expensive.\n",
    "- Houses with less rooms as well - this might be a correction factor to a large influence of AveBedrooms: More rooms increase the housing price as long as there are enough beds/bedrooms. Alternatively, a large number of rooms might indicate a large number of houses used only for the holidays.\n",
    "- The popoulation in this area has no influence on the price.\n",
    "- The larger households are, the less expensive the houses get (for a fixed number of rooms). In thise sense, more spacious houses are more expensive. \n",
    "- Southern and western areas are more expensive than northeastern ones. (This could be a potential influence of LA and SF)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c15a9a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary \n",
    "\n",
    "- There are I/O- and CPU-bound problems\n",
    "- Use `threading` for I/O-bound problems, `multiprocessing` for CPU-bound problems\n",
    "- Communication between processes is cumbersome\n",
    "- For many CPU-bound tasks, there may be implemented solutions. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "rise": {
   "progress": true,
   "scroll": true,
   "theme": "white"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
