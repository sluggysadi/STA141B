{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff704263",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### STA 141B Data & Web Technologies for Data Analysis\n",
    "\n",
    "### Lecture 9, 02/03/26, APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84104dba-1ba1-4e8d-beca-8b223c4025b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Announcements:\n",
    "\n",
    "- Second homework assignment to be uploaded soon on Gradescope. Deadline is __02/13/26__.\n",
    "- Please register your group if you haven't done so yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d6f0bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Today's topics\n",
    "\n",
    "\n",
    "- Final Project\n",
    "- Getting Data from the Web\n",
    "- Hypertext Transfer Protocol\n",
    "- Representational State Transfer\n",
    "- iTunes API\n",
    "- Caching\n",
    "- API Keys\n",
    "- Guardian API\n",
    "\n",
    "### Resources\n",
    " - [iTunes Search API](https://affiliate.itunes.apple.com/resources/documentation/itunes-store-web-service-search-api/)\n",
    " - [Guardian API](https://open-platform.theguardian.com/documentation/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b57019-4920-42d8-8f5d-1d116a3e2ef1",
   "metadata": {},
   "source": [
    "### Final Project\n",
    "\n",
    "You should work in groups with three to four students. The\n",
    "purpose of the project is to provide you with real data aquisition experience,\n",
    "which includes:\n",
    "\n",
    "Good practice (simplified):\n",
    "- __Think__ of a good research questions\n",
    "- __Find__ data sources on the web\n",
    "- __Access__ the data via API / manual scraping / selenium browser\n",
    "- __Store__ the data either in a DB via SQLite3 or smaller datasets in csv files\n",
    "- __Process__ the data as pandas DataFrame\n",
    "- __Visualize__ your findings via seaborn / plotnine / folium / flipbook\n",
    "- __Present__ your work: Write the report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f593738f-1791-4214-a692-300cb849c262",
   "metadata": {},
   "source": [
    "#### Getting Started\n",
    "\n",
    "To narrow down your project to just one topic, think\n",
    "about:\n",
    "\n",
    "*   What questions does your topic address or what problems does your topic\n",
    "    solve? Why and to whom are these meaningful?\n",
    "*   What's challenging about your topic?\n",
    "*   Are there credible, **public** datasets available to explore the topic?\n",
    "    See below for some suggested data sources.\n",
    "*   Is a 6-week project long enough to explore the topic reasonably well?\n",
    "\n",
    "As inspiration and an example of what can be done with public datasets, see [I\n",
    "Quant NY][NY]. \n",
    "\n",
    "[NY]: http://iquantny.tumblr.com/post/144197004989/the-nypd-was-systematically-ticketing-legally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf2af8c-f256-4018-a3c2-90eec28f1322",
   "metadata": {},
   "source": [
    "#### Grading criteria\n",
    "\n",
    "The final report is due on __March 15__. The report should be 6-10 pages\n",
    "including writing and visualizations, but excluding code. \n",
    "\n",
    "We will score your report according to:\n",
    "\n",
    "* Reporting: Are there clear research questions that you asked, and did you\n",
    "    address these in an orderly fashion? Did you make well justified\n",
    "    conclusions? Is your project sensible and easy to read?\n",
    "* Data Aquisition and Processing:  How much work was necessary to get your data,\n",
    "    which includes web APIs, web scraping, and reading data from files. \n",
    "    Did you process the data in an clear, efficient,\n",
    "    and organized way? Do you join multiple data sources appropriately? Did you\n",
    "    work with unstructured data? Did you store your processed data in an\n",
    "    efficient way, using well-thought-out data structures or a database?\n",
    "* Vizualisation and Methodology: \n",
    "    Do your visualizations follow best practices? Do they support the hypothesis? \n",
    "    Is your methodology appropriate? \n",
    "    Does this give insight to your project? Are the methods tailored to your\n",
    "    specific topic and data (not generic or off-the-shelf)?\n",
    "* Code: Is your code well-organized and easy to read? Is your code\n",
    "    reproducible? Is your code documented? Is your code reasonably efficient?\n",
    "    Did you use appropriate data structures and algorithms?\n",
    "\n",
    "#### Grading scales:\n",
    "\n",
    "Grade            | Points\n",
    "------------     | -------\n",
    "Good             | 35\n",
    "Satisfactory     | 28\n",
    "Poor             | 21\n",
    "Partial Work     | 14\n",
    "No Work          | 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a76a0ce-a95a-4644-be8e-d9ce78f520b3",
   "metadata": {},
   "source": [
    "#### Usage of AI\n",
    "\n",
    "Note that you are not allowed to use AI for writing the report. The only legal use of AI is for simple code snippets. These cases must be highlighted as AI output.\n",
    "I reserve the right to perform an AI check for the final project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047309bc-8f24-4106-988d-d2bdb53eea88",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ccd60",
   "metadata": {},
   "source": [
    "### Getting Data from the Web\n",
    "\n",
    "We consider three ways one can get data from the web, from most to least convenient:\n",
    "1. Direct download\n",
    "2. API\n",
    "3. Scraping\n",
    "\n",
    "Always look for a direct download first!\n",
    "\n",
    "#### Difference between web scraping and API\n",
    "\n",
    "_Web Scraping_ refers to the process of extracting data from a website or specific webpage.\n",
    "\n",
    "API stands for _application programming interface_ (API) is a collection of functions and data structures for communicating with other software. For instance, whenever you use a Python package, you're using the API created by the package's developers.\n",
    "\n",
    "The goal of both web scraping and (web) APIs is to access web data.\n",
    "\n",
    "Web scraping allows you to extract data from any website through the use of web scraping software. On the other hand, APIs give you direct access to the data you want.\n",
    "\n",
    "Websites sometimes provide an API so that programmers can access content without web scraping. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789a17e5",
   "metadata": {},
   "source": [
    "### Hypertext Transfer Protocol\n",
    "\n",
    "The hypertext transfer protocol (HTTP) is a set of rules for communicating over the internet.\n",
    "\n",
    "For example, your web browser uses HTTP every time you visit a web page. The browser makes a _request_ to the server for the page, and if nothing goes wrong, the server _responds_ with the page. If you have Firefox or Chrome, you can inspect these requests with your browser's web developer tools (Windows: <kbd>Ctrl</kbd> + <kbd>i</kbd>; MacOS: <kbd>&#8984;</kbd> + <kbd>&#8997;</kbd> + <kbd>i</kbd>).\n",
    "\n",
    "Several [different kinds of HTTP requests](https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol#Request_methods) are possible. Think of these as the different \"verbs\" you can use when communicating in HTTP.\n",
    "\n",
    "Many protocols exist for communicating over the internet. For instance, you may have heard of _file transfer protocol_ (FTP) for transferring files, or _simple mail transfer protocol_ (SMTP) for sending/receiving email. However, web APIs almost always use HTTP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f833f87",
   "metadata": {},
   "source": [
    "A response to an HTTP request always includes a status code that summarizes whether the request was successful. Wikipedia has a full [list of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes). Generally,\n",
    "\n",
    "* 200-299: Your request succeeded.\n",
    "* 300-399: You need to take further action to complete the request.\n",
    "* 400-499: Your request wasn't valid (you made a mistake). You've probably seen 404 before!\n",
    "* 500-599: Your request failed (the server made a mistake)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b912b2",
   "metadata": {},
   "source": [
    "### Representational State Transfer \n",
    "\n",
    "The most popular kind of web API is a _representational state transfer_ (REST) API. The API needs to meet the following architectural requirements to be considered a REST API:\n",
    "\n",
    "- Client-server: REST applications have a server that manages application data and state. \n",
    "- Stateless: Servers don’t maintain client state, clients manage their own application state. The client’s requests to the server contain all the information required to process them.\n",
    "- Cacheable: servers must mark their responses as cacheable or not. Systems and clients can cache responses when convenient to improve performance. \n",
    "- Uniform interface: This is REST’s most well-known feature or rule. \n",
    "\n",
    "The URL with which we can talk to the server is sometimes called *endpoint*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed225a4",
   "metadata": {},
   "source": [
    "### iTunes API\n",
    "\n",
    "We use the iTunes API at `https://itunes.apple.com/search`, see [documentation](https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/iTuneSearchAPI/Searching.html#//apple_ref/doc/uid/TP40017632-CH5-SW1). \n",
    "\n",
    "Note that the API is restricted to 20 calls per minute.\n",
    "\n",
    "When you first use a web API, check the documentation to find out what the endpoints are and what kind of HTTP requests to use. If the documentation doesn't mention what kind of HTTP request to use, then GET is usually the right choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9250f35d",
   "metadata": {},
   "source": [
    "#### Making Requests\n",
    "\n",
    "Python's `requests` package provides functions for making HTTP requests. Let's use the endpoint we learned from the iTunes API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bd9670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2898ddd1",
   "metadata": {},
   "source": [
    "The syntax for the `requests` package is `response = requests.get(\"WEBSITE ADDRESS\")`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5340d169",
   "metadata": {},
   "source": [
    "#### Query Strings\n",
    "\n",
    "Most of the functions we use have parameters, and you can pass arguments for those parameters when you call a function.\n",
    "\n",
    "Endpoints in REST APIs work the same way, but the syntax is different. You can pass arguments by adding `?PARAMETER=ARGUMENT` to the end of the URL. Parameter and argument pairs are separated by `&`. This syntax is called a _query string_.\n",
    "\n",
    "The search endpoint is `https://itunes.apple.com/search`, and the documentation lists several parameters. We can use `requests` to build the query string automatically.\n",
    "\n",
    "Lets answer the question: How many albums of *Taylor Swift* are on iTunes? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fa83ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the User-Agent header\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "response = requests.get(\"https://itunes.apple.com/search\", headers=headers, params = {\n",
    "        \"term\": \"swift\", # add multiple terms via +\n",
    "        \"media\": \"music\",\n",
    "        \"entity\": \"album\",\n",
    "        \"attribute\": \"artistTerm\", # check iTunes docs\n",
    "        \"country\": \"US\", \n",
    "        \"limit\": \"4\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226b748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba6cfda-fb71-49ee-872d-4f09d8b7f30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a5daa2-b72e-4e31-bd2e-692dfbcddab9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513df72d-0279-4917-bdcb-f63cbab56aa7",
   "metadata": {},
   "source": [
    "To see the actual query, we can just look at the url:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8cec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d91a7f-0995-4bf6-8395-46cb0e89e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ec783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d63224",
   "metadata": {},
   "source": [
    "You can have `requests` check the status for you with the `.raise_for_status()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896fc0f0-5472-46bc-ac64-51ef3f5f8ee1",
   "metadata": {},
   "source": [
    "##### raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e8565a-6bc2-4c13-b825-3fc1faf5e142",
   "metadata": {},
   "source": [
    "Just to see what happens if we make a mistake here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b50013-24f6-4e5f-8f99-cfd9c12fc246",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://itunes.apple.com/search\", headers=headers, params = {\n",
    "        \"term\": \"swift\", \n",
    "        \"media\": \"music\",\n",
    "        \"entity\": \"album\",\n",
    "        \"attribute\": \"artistSTerm\", # artistSTerm is no valid attribute! \n",
    "        \"country\": \"US\", \n",
    "        \"limit\": \"4\" \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9a4180",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60075d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0f0bd1-75bb-4944-b785-64bac22856f9",
   "metadata": {},
   "source": [
    "Let's stick to the correct parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca2460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://itunes.apple.com/search\", headers=headers, params = {\n",
    "        \"term\": \"swift\", \n",
    "        \"media\": \"music\",\n",
    "        \"entity\": \"album\",\n",
    "        \"attribute\": \"artistTerm\", # artistsTerm is no valid attribute! \n",
    "        \"country\": \"US\", \n",
    "        \"limit\": \"4\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a2b6f1-562b-4c6e-aec0-753cf99b86e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274aeab9",
   "metadata": {},
   "source": [
    "Once you have the response, now what? Where's the data? Different web APIs use different formats. Again, see the documentation. Two common formats are:\n",
    "\n",
    " - _JavaScript Object Notation_ (JSON): JSON looks and works a lot like Python lists and dictionaries. Lists are surrounded with `[ ]`, and dictionaries are surrounded with `{ }`. There are many Python libraries for reading JSON into lists and dictionaries. Jupyter notebooks are an example of a file in JSON format.\n",
    "\n",
    " - _eXtensible Markup Language_ (XML): XML uses \"tags\" denoted by `< >` to mark up sections of text. We'll learn more about XML when we learn about web scraping, since XML is very similar to hypertext markup language (HTML), the language used to build web pages.\n",
    "\n",
    "The iTunes returns data in JSON format (derived from JavaScript). We can inspect the raw content (bytes) of a response with the `.content` attribute. If we know the response is in a text format, we can use `.text` to see the content as an ordinary Python string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada09be5-c26c-459f-bb64-d4e12de20e2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d887e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2587d2",
   "metadata": {},
   "source": [
    "Since the response we got is in JSON format, we'd like to convert the string to lists and dictionaries. The `requests` package provides a method `.json()` to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424b81b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = response.json()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb97d60-13d6-4950-95c9-f4a7c4bb42af",
   "metadata": {},
   "source": [
    "So how can we get the actual result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7e7b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d1f419-095c-4c5c-9108-92d35561d452",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(result.keys())) # N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4b680b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45609a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.DataFrame(result['results'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d9c3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f897ce4b-6acd-43cc-a6f6-83d97278a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N\n",
    "# for comparison\n",
    "print(result[\"resultCount\"])\n",
    "print(len(result[\"results\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22237d2-da4b-4ce9-9461-9023d3402c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N\n",
    "cols = list(results.columns)\n",
    "c2 = list(result[\"results\"][0].keys())\n",
    "print(c2)\n",
    "print(cols)\n",
    "print(c2 == cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b36bf5-eabf-4022-95d9-f53a91d36dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N\n",
    "import numpy as np\n",
    "cols = np.array(cols)\n",
    "c2 = np.array(c2)\n",
    "cols[np.isin(cols, c2, invert = True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972cec14",
   "metadata": {},
   "source": [
    "### Caching\n",
    "\n",
    "Making an HTTP request is not free! It has a real cost in CPU time and also cash. Server administrators will not appreciate it if you make too many requests or make requests too quickly. So:\n",
    "\n",
    "* Use `time.sleep()` to slow down any requests you make in a loop. Aim for no more than 20-30 requests per second.\n",
    "* Install and use the `requests_cache` package to avoid downloading extra data when you make the same request twice.\n",
    "\n",
    "Failing to be polite can get you banned from websites!\n",
    "\n",
    "We can use `sleep` from `time` to suspend any operation for the passed number of seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf44d337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "print(time.ctime())\n",
    "time.sleep(5)\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9183f06d",
   "metadata": {},
   "source": [
    "A possible problem for time consuming requests is that data is requested multiple times. This can be avoided by using a cache. When the request is made, it first checks the cache. Only if the data is not found there, the data is pulled from the server and copied into the cache. \n",
    "\n",
    "We cache our search results with `requests_cache` ([docs](https://requests-cache.readthedocs.io/en/stable/user_guide.html)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580bda00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "session = requests.Session() \n",
    "print(time.ctime())\n",
    "for i in range(5):\n",
    "    session.get('http://httpbin.org/delay/1') # this endpoints delays by one second\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1c1e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests_cache\n",
    "session = requests_cache.CachedSession('demo_cache')\n",
    "print(time.ctime())\n",
    "for i in range(5):\n",
    "    res = session.get('http://httpbin.org/delay/1')\n",
    "    res.raise_for_status()\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ff11d0-34a1-4c49-a0bc-a057eb321520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "session = requests.Session() \n",
    "print(time.ctime())\n",
    "for i in range(20):\n",
    "    session.get('https://homepage.univie.ac.at/nicolai.amann/')\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b86348d-e392-4643-b5e9-73554049f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests_cache\n",
    "session = requests_cache.CachedSession('demo_cache')\n",
    "print(time.ctime())\n",
    "for i in range(20):\n",
    "    res = session.get('https://homepage.univie.ac.at/nicolai.amann/')\n",
    "    res.raise_for_status()\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a188ac-f11d-47df-a8e6-92d0b72d9fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40666a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da41fdf8-acea-420b-97f5-9109a125900c",
   "metadata": {},
   "source": [
    "Note that this returns HTML and not a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b749a25f-60c1-4ef7-b89c-bb3791971bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.json() # throws an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0c9b3d-27d6-4170-8689-ad3d0cd74922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43b26e9a",
   "metadata": {},
   "source": [
    "### API Keys\n",
    "\n",
    "Many APIs use a _key_ or _token_ to identify the user. For instance, The Guardian, a British newspaper, provides a [web API](https://open-platform.theguardian.com/) to access their news articles. You need an API key to use their web APIs. You can get one for free [here](https://bonobo.capi.gutools.co.uk/register/developer).\n",
    "\n",
    "#### Storing API Keys\n",
    "\n",
    "Your API key is private and your responsibility. Treat it like a password. Keep it secret! \n",
    "\n",
    "In order to keep your API key separate from your code:\n",
    "1. Save the API key in a text file.\n",
    "2. Use Python to load the API key into a variable.\n",
    "\n",
    "Python's built-in `open()` function opens a file, and the `.readline()` method reads a line from a file. Often you'll see these used with `with`, which automatically closes the file at the end of the block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36efeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_key(keyfile):\n",
    "    with open(keyfile) as f:\n",
    "        return f.readline().strip(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b37d429",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = read_key(\"../keys/guardian.txt\") # Don't print out your actual API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e288d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5489ff",
   "metadata": {},
   "source": [
    "Now you can use the `key` variable anywhere you need the actual API key."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725d413d",
   "metadata": {},
   "source": [
    "#### Querying The Guardian\n",
    "\n",
    "We've got our key, so let's use The Guardian API. \n",
    "\n",
    "We want to answer the question whether Harris or Trump get more newspaper coverage in the days leading up to the 2024 U.S. presidential election. Let's start by trying to get all of the articles about one of the candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba089b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://content.guardianapis.com/search\", params = {\n",
    "        \"api-key\": key,\n",
    "        \"q\": \"Harris\",\n",
    "        \"from-date\": \"2024-10-30\",\n",
    "        \"to-date\": \"2024-11-05\",\n",
    "        \"page-size\": 50,\n",
    "        \"order_by\": \"newest\",\n",
    "        \"page\": 1\n",
    "    }) # try page 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1daf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.raise_for_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea0682",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3962d1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def get_articles(q, page = 1, from_date = \"2024-10-30\"):\n",
    "    time.sleep(0.05) \n",
    "    response = requests.get(\"https://content.guardianapis.com/search\", params = {\n",
    "        \"api-key\": key,\n",
    "        \"q\": q,\n",
    "        \"from-date\": from_date,\n",
    "        \"to-date\": \"2024-11-05\",\n",
    "        \"page-size\": 50,\n",
    "        \"order_by\": \"newest\", \n",
    "        \"page\": page\n",
    "    })\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29c5881",
   "metadata": {},
   "outputs": [],
   "source": [
    "harris = get_articles(\"Harris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084a161b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "harris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6d7312",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = harris[\"pages\"]\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fd9813",
   "metadata": {},
   "outputs": [],
   "source": [
    "pageSize = harris[\"pageSize\"]\n",
    "pageSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811e7104",
   "metadata": {},
   "outputs": [],
   "source": [
    "currentPage = harris[\"currentPage\"]\n",
    "currentPage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe8f6b0-96eb-4723-9e01-8f935bde3e0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_articles(\"Harris\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9abe35-e7f3-430c-a1b9-0c64365dc532",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_articles(\"Harris\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18f2bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = harris[\"results\"]\n",
    "for p in range(2, pages + 1):\n",
    "    results += get_articles(\"harris\", p)[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0563b5d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe96ced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a172a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545ebb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a4a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efd86a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"webPublicationDate\"] = pd.to_datetime(df[\"webPublicationDate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388ab910",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df[\"webPublicationDate\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1020100a-3761-4723-b9e6-dd54052b36a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"webPublicationDate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca0e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efe4320",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = df[\"webPublicationDate\"].dt\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbbfa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "date.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf79cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.DataFrame({\"day\": date.day, \"day_name\": date.day_name()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9513c12a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c956922",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dates.groupby([\"day\", \"day_name\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5211ad",
   "metadata": {},
   "source": [
    "Write it as a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4317858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles(q, page = 1):\n",
    "    response = requests.get(\"https://content.guardianapis.com/search\", params = {\n",
    "        \"api-key\": key,\n",
    "        \"q\": q,\n",
    "        \"from-date\": \"2024-10-30\",\n",
    "        \"to-date\": \"2024-11-05\",\n",
    "        \"page-size\": 50,\n",
    "        \"page\": page\n",
    "    })\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b412d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_articles(q, time_sleep = 0.05):\n",
    "    # Get the first page, and find out how many pages there are.\n",
    "    candidate = get_articles(q)\n",
    "    pages = candidate[\"pages\"]\n",
    "\n",
    "    # Loop over remaining pages.\n",
    "    results = candidate[\"results\"]\n",
    "    for p in range(2, pages + 1):\n",
    "        results += get_articles(q, p)[\"results\"]\n",
    "        time.sleep(time_sleep)\n",
    "\n",
    "    # Convert the articles to data frame, and the date column to a date.\n",
    "    df = pd.DataFrame(results)\n",
    "    df[\"webPublicationDate\"] = pd.to_datetime(df[\"webPublicationDate\"])\n",
    "    \n",
    "    # Get the day and day name, then count them.\n",
    "    date = df[\"webPublicationDate\"].dt\n",
    "    dates = pd.DataFrame({\"day\": date.day, \"day_name\": date.day_name()})\n",
    "    dates.loc[dates.day == 30, \"day\"] = -1\n",
    "    dates.loc[dates.day == 31, \"day\"] = 0\n",
    "    return dates.groupby([\"day\", \"day_name\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0fa9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "harris=get_all_articles(\"Kamala Harris\")\n",
    "harris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43a26c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "harris.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e6d626",
   "metadata": {},
   "outputs": [],
   "source": [
    "trump=get_all_articles(\"Donald Trump\")\n",
    "trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336ab61a-0fe1-4dd0-be6b-d548b93e302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([harris,trump]).T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482bc398",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([harris,trump]).T\n",
    "df = df.rename(columns={0: 'Harris', 1: 'Trump'})\n",
    "df = df.reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fba6d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.melt(id_vars = ['day', 'day_name'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e6c872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotnine as p9\n",
    "(\n",
    "    p9.ggplot(df, p9.aes(x='day',y='value',color='variable')) + \n",
    "        p9.geom_line() + \n",
    "    p9.labs(color='',x='Day',y='Number of articles')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d50132",
   "metadata": {},
   "source": [
    "What are some ways this analysis could be improved?\n",
    "\n",
    "* Check that articles about \"Trump\" and \"Harris\" are actually about the two candidates. Some may be about other things -- the English word \"trump\" etc...\n",
    "* Check whether the API searches article text or just article titles.\n",
    "* Use more sources, and use American newspapers (unless the goal was to analyze international news).\n",
    "* Make visualizations.\n",
    "* Use a larger time window.\n",
    "* Use other kinds of data (e.g., poll results) to look for relationships.\n",
    "\n",
    "Collecting and cleaning data takes a lot of very technical work, but it's only the first step in the analysis. When you finish data collection and cleaning, it can feel like you're finally done. Take a moment to congratulate yourself and step away from the data, so that when you come back you'll be ready to do a careful statistical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4842a995",
   "metadata": {},
   "source": [
    "### OAuth\n",
    "\n",
    "[OAuth](https://en.wikipedia.org/wiki/OAuth) is a way to give an application access to data on a website or web API.\n",
    "\n",
    "You might run into OAuth if you use a web API where the data is private. For instance, Twitter provides a [web API](https://developer.twitter.com/en/docs.html) for managing your personal Twitter account. If you want to access the API from a Python script, first you have to use OAuth to tell Twitter that the script has permission to use your data.\n",
    "\n",
    "OAuth can operate in several different ways. As always, check the documentation for the web API you want to use in order to find out what you need to do.\n",
    "\n",
    "The simplest case of OAuth requires scripts to have a key or token from the web API provider. This is very similar to using an API key.\n",
    "\n",
    "For more complicated cases, the `requests-ouathlib` package ([docs](https://requests-oauthlib.readthedocs.io/en/latest/)) may help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c15a9a",
   "metadata": {},
   "source": [
    "### Summary \n",
    "\n",
    "- Third parties provide access to their data bases via APIs\n",
    "- Check API documentation to assemble a valid query\n",
    "- You are a guest, be polite! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f9bdb1-9a37-4197-8d3a-a3ed2eaa2fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
